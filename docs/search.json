[
  {
    "objectID": "d20220921.html#harug-hello-world-using-quarto",
    "href": "d20220921.html#harug-hello-world-using-quarto",
    "title": "2022-09-21",
    "section": "HARUG “Hello world” using Quarto",
    "text": "HARUG “Hello world” using Quarto\nNew HARUG! webpage using Quarto and Github Pages.\nQuarto is a new(ish) markdown-style language that has a very simple workflow and can be use to make sophisticated webpages, slides, and reports.\nWhile it is probably easier and more modern than plain markdown or R Markdown, a big advantage is that it can be used to make documents with live code for a variety of languages, including both R and Python.\nQuarto website\nOFFICIAL documentation (excellent)\nGood blog post about setting a quarto website up"
  },
  {
    "objectID": "d20220921.html#you-can-render-and-use-both-r-and-python-in-quarto",
    "href": "d20220921.html#you-can-render-and-use-both-r-and-python-in-quarto",
    "title": "2022-09-21",
    "section": "You can render and use both R and python in Quarto",
    "text": "You can render and use both R and python in Quarto\n\n# Python in Quarto\nprint('hello world')\n\nhello world\n\n\n\n# R in Quarto\nprint(\"hello world\")\n\n[1] \"hello world\"\n\n\n\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "d20220928.html#computer-vision-project-python-matt",
    "href": "d20220928.html#computer-vision-project-python-matt",
    "title": "2022-09-28",
    "section": "Computer vision project / Python (Matt)",
    "text": "Computer vision project / Python (Matt)\n\n\n\n\n\npptx\nweevilwatch github repo\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "d20221005.html#quarto-r-markdowns-new-clothes",
    "href": "d20221005.html#quarto-r-markdowns-new-clothes",
    "title": "2022-10-05",
    "section": "Quarto: R Markdown’s “new clothes”?",
    "text": "Quarto: R Markdown’s “new clothes”?\nOur \\(10^2\\) meeting! (Ed)\nThe goal here is to make a Quarto website using RStudio, then deploy it to Github pages in an organization repository\nQuarto is a markdown language system used to generate websites and other documents (like pdf, word, html talk slides) that automatically generates all of the formatting framework for you. I.e. you can make a modern, sophisticated website without having to learn html, javascipt, css, etc. There are other tools that can let you do this, but here it is open source, reproducible, integrated into RStudio, and unreliant on third party solutions.\nPreparation\n\nLatest version of RStudio installed\nLatest version of Quarto for RStudio installed\nHave a free Github account\nLatest version of Github Desktop installed"
  },
  {
    "objectID": "d20221005.html#github-setup",
    "href": "d20221005.html#github-setup",
    "title": "2022-10-05",
    "section": "1 Github setup",
    "text": "1 Github setup\nYou can choose to use your personal account or make a free Github organization owned by your personal account.\nThe advantage of making a github organization here is that it can have a github pages repo, without using the one on your personal account. You can skip this step if you prefer to make this tutorial site using your personal github account github page.\n\n\n1.1 Create github organization\nCreate your organization (I recommend) using the account details matching you main github account. You can add the remaining details as you wish for your organization.\n\n\n\n\nChoose Create a free organization\nOrg. name, (main account) email\n\n\n\n\n\n\n1.2 Create repository\n\nCreate a new repository:\n\nChoose repo name (e.g. ‘website’)\nMake public\nClick Create Repository\n\n\n\n\n\n\n1.3 Local repo\n\n\nset up in Github Desktop (or other means you prefer)\n\n\n\n\nFrom Github Desktop, make a local path for the repo\n\n\n\n\n\nExamine your local directory"
  },
  {
    "objectID": "d20221005.html#quarto-website",
    "href": "d20221005.html#quarto-website",
    "title": "2022-10-05",
    "section": "2 Quarto website",
    "text": "2 Quarto website\nHere we will use RStudio to set up a Quarto website and adjust a few settings\n\n2.1 New project\nIn RStudio:\n\nCreate a new project\nChoose Existing Directory\nbrowse to your local repo folder (/website, if you follow my example)\n\n\n\n\n\n2.2 Create Quarto website template\nNow in the RStudio Terminal tab (the Terminal tab, not the Console tab…), type:\n\nTerminal\n\nquarto create-project --type website\nTerminal output:\n\nFiles output:"
  },
  {
    "objectID": "d20221005.html#basic-quarto-editing",
    "href": "d20221005.html#basic-quarto-editing",
    "title": "2022-10-05",
    "section": "3 Basic quarto editing",
    "text": "3 Basic quarto editing\nWe are going to set up the most basic quarto website that has two Sections, each with one webpage.\n\n3.1 _quarto.yaml\nYAML stands for “YAML Ain’t Markdown Language”\nMarkdown is a language designed to easily format plain text into modern HTML, which can get complicated\nHTML is HyperText Markup Language, which formats web content documents\nYour _quarto.yaml file allows you to control formatting on your website in a very terse way. There are many options, but they are easy to use and the documentation is very good (see Resources below).\nBasically we are going to:\n\nmake a website type document\nset the output directory for html\nmake sidebar navigation\nset the theme for our website\nenable the “visual” editor in RStudio (slightly buggy but useful)\n\n\n\n3.2 Default YAML\nOpen your _quarto.yaml file in the RStudio editor.\n    project:                << project type\n      type: website\n\n    website:                << website options\n      title: \"website\"      << title\n      navbar:               << navbar options\n        left:\n          - href: index.qmd\n            text: Home\n          - about.qmd\n\n    format:                 << themes and aesthetics\n      html:\n        theme: cosmo\n        css: styles.css\n        toc: true\nWe can quickly see visually how this default YAML file “renders” your website. RStudio will automatically generate .html pages based on code in your .qmd files (our default website has only one .qmd, but a website will typically have more). Then RStudio will launch a “local server” to “host” your rendered website on your local browser to preview it. Let’s do that now:\n\nOpen the index.qmd file in RStudio\nNotice the Quarto Render button\nClick Render!\n\n\n\nYour new website should look like this:\n\n\n\n3.3 Custom YAML\nCustomizing your .yaml file is The Way () to customize your website.\nCopy and past the new yaml below into your _quarto.yaml file. This will:\n\nDirect html outputs to a docs subfolder\nCustomize the website title (use your own)\nCreate a “docked” navigation system\nChange the html theme\nAdd a user-interactive theme button\n\n\nproject:\n  type: website\n  output-dir: docs\n\nwebsite:\n  title: \"R Stats Bootcamp\"\n  sidebar:\n#    logo: \n    style: \"docked\"\n    search: true\n    contents: \n      - section: \"Information\"\n        contents:\n          - index.qmd\nformat:\n  html:\n    highlight-style: a11y\n    theme:\n      light: flatly\n      dark: darkly\n    css: styles.css\n    toc: true\n\neditor: visual\nNow save it and hit render!\n A. The locally hosted address\nB. The site title\nC. The theme button (dark chosen here)\nD. The Section and page links\n\n\n3.4 .nojekyll\nA strength of Quarto is that is does all of the clever stuff for nice webpages and we can use this on Github. However, Github does some of this by default (far less cleverly). We want to turn this off. There is an easy way to do this by creating an empty placeholder document called .nojekyll in your repo root directory. The presence of this file tells github not to render the markdown by it’s own system (their system being called “Jekyll”).\nNote in the RStudio Terminal (which emulates Linux for [sic] Windoze users)\n\nIn your Terminal window:"
  },
  {
    "objectID": "d20221005.html#configuring-github-pages",
    "href": "d20221005.html#configuring-github-pages",
    "title": "2022-10-05",
    "section": "4 Configuring github pages",
    "text": "4 Configuring github pages\nNow you have a test website you can experiment with and populate with content. First let’s see how the live version looks on the web.\n\n4.1 Push changes to Github\nBack to Github Desktop.\n There have been some changes!\nA. A list of your changed files\nB. Summary field you must provide (describe changes)\nC. Detail of the changes\nD. The Commit button\nFor now, enter a brief Summary (e.g., “site initialization”), and hit the commit button.\nThe repository will update and the Publish branch button will appear - hit it!\n\n\n\n4.2 Github account\nAfter a few minutes your Github repository will update to be identical to your local copy of the repo.\nNavigate to the repository on your organization account.\n A. Navigate to your repo\nB. Click the Settings tab\nC. Click the Pages option\nD. Choose main on the Branch dropdown\n\n A. Now select /docs on the Select folder dropdown (remember we set output to this folder…)\n\n\n4.3 View your site\nThe format of a Github pages wesite URL (i.e. web address) is like this:\n.github.io/\nE.g.: https://rstats-bootcamp.github.io/website/"
  },
  {
    "objectID": "d20221005.html#develop-your-own-page",
    "href": "d20221005.html#develop-your-own-page",
    "title": "2022-10-05",
    "section": "5 Develop your own page",
    "text": "5 Develop your own page"
  },
  {
    "objectID": "d20221005.html#resources",
    "href": "d20221005.html#resources",
    "title": "2022-10-05",
    "section": "Resources",
    "text": "Resources\nQuarto website\nOFFICIAL documentation (excellent)\nGood blog post about setting a quarto website up\n\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "d20221026.html#quarto-r-markdowns-new-clothes",
    "href": "d20221026.html#quarto-r-markdowns-new-clothes",
    "title": "2022-10-05",
    "section": "Quarto: R Markdown’s “new clothes”?",
    "text": "Quarto: R Markdown’s “new clothes”?\n\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "(old website)\n\nHARUG! is the Harper Adams R User Group\nThis site is devoted to the R programming, Python, Statistics and Data Science community at Harper Adams University. We meet Wednesdays at 4pm UK time on Teams and via our Slack workspace anytime (please join with your full real name, e.g. “Florence Nightingale”).\n Slack workspace: Join us (kindly register with your real name, e.g. “Ronald Fisher”)\n Youtube channel\n\nResearch methods in statistics and AI applications\nBuild data analysis skills and capacity\nGroup problem solving, live coding\nTutorials and resource sharing\nCommunity\n\n\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "ipynb/d20221005.html#quarto-r-markdowns-new-clothes",
    "href": "ipynb/d20221005.html#quarto-r-markdowns-new-clothes",
    "title": "2022-10-05",
    "section": "Quarto: R Markdown’s “new clothes”?",
    "text": "Quarto: R Markdown’s “new clothes”?\nOur \\(10^2\\) meeting! (Ed)\nThe goal here is to make a Quarto website using RStudio, then deploy it to Github pages in an organization repository\nQuarto is a markdown language system used to generate websites and other documents (like pdf, word, html talk slides) that automatically generates all of the formatting framework for you. I.e. you can make a modern, sophisticated website without having to learn html, javascipt, css, etc. There are other tools that can let you do this, but here it is open source, reproducible, integrated into RStudio, and unreliant on third party solutions.\nPreparation\n\nLatest version of RStudio installed\nLatest version of Quarto for RStudio installed\nHave a free Github account\nLatest version of Github Desktop installed"
  },
  {
    "objectID": "ipynb/d20221005.html#github-setup",
    "href": "ipynb/d20221005.html#github-setup",
    "title": "2022-10-05",
    "section": "1 Github setup",
    "text": "1 Github setup\nYou can choose to use your personal account or make a free Github organization owned by your personal account.\nThe advantage of making a github organization here is that it can have a github pages repo, without using the one on your personal account. You can skip this step if you prefer to make this tutorial site using your personal github account github page.\n\n\n1.1 Create github organization\nCreate your organization (I recommend) using the account details matching you main github account. You can add the remaining details as you wish for your organization.\n\n\n\n\nChoose Create a free organization\nOrg. name, (main account) email\n\n\n\n\n\n\n1.2 Create repository\n\nCreate a new repository:\n\nChoose repo name (e.g. ‘website’)\nMake public\nClick Create Repository\n\n\n\n\n\n\n1.3 Local repo\n\n\nset up in Github Desktop (or other means you prefer)\n\n\n\n\nFrom Github Desktop, make a local path for the repo\n\n\n\n\n\nExamine your local directory"
  },
  {
    "objectID": "ipynb/d20221005.html#quarto-website",
    "href": "ipynb/d20221005.html#quarto-website",
    "title": "2022-10-05",
    "section": "2 Quarto website",
    "text": "2 Quarto website\nHere we will use RStudio to set up a Quarto website and adjust a few settings\n\n2.1 New project\nIn RStudio:\n\nCreate a new project\nChoose Existing Directory\nbrowse to your local repo folder (/website, if you follow my example)\n\n\n\n\n\n2.2 Create Quarto website template\nNow in the RStudio Terminal tab (the Terminal tab, not the Console tab…), type:\n\nTerminal\n\nquarto create-project --type website\nTerminal output:\n\nFiles output:"
  },
  {
    "objectID": "ipynb/d20221005.html#basic-quarto-editing",
    "href": "ipynb/d20221005.html#basic-quarto-editing",
    "title": "2022-10-05",
    "section": "3 Basic quarto editing",
    "text": "3 Basic quarto editing\nWe are going to set up the most basic quarto website that has two Sections, each with one webpage.\n\n3.1 _quarto.yaml\nYAML stands for “YAML Ain’t Markdown Language”\nMarkdown is a language designed to easily format plain text into modern HTML, which can get complicated\nHTML is HyperText Markup Language, which formats web content documents\nYour _quarto.yaml file allows you to control formatting on your website in a very terse way. There are many options, but they are easy to use and the documentation is very good (see Resources below).\nBasically we are going to:\n\nmake a website type document\nset the output directory for html\nmake sidebar navigation\nset the theme for our website\nenable the “visual” editor in RStudio (slightly buggy but useful)\n\n3.1 Default YAML\nOpen your _quarto.yaml file in the RStudio editor.\nproject:\n  type: website\n\nwebsite:\n  title: \"website\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - about.qmd\n\nformat:\n  html:\n    theme: cosmo\n    css: styles.css\n    toc: true"
  },
  {
    "objectID": "ipynb/d20221005.html#resources",
    "href": "ipynb/d20221005.html#resources",
    "title": "2022-10-05",
    "section": "Resources",
    "text": "Resources\nQuarto website\nOFFICIAL documentation (excellent)\nGood blog post about setting a quarto website up\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "pages/2022-12-07-flexdashboard/example/example.html",
    "href": "pages/2022-12-07-flexdashboard/example/example.html",
    "title": "Flexdashboard example",
    "section": "",
    "text": "plot(rnorm(10), rnorm(10))"
  },
  {
    "objectID": "pages/2022-12-07-flexdashboard/example/example.html#column-1",
    "href": "pages/2022-12-07-flexdashboard/example/example.html#column-1",
    "title": "Flexdashboard example",
    "section": "Column",
    "text": "Column\n\nChart B\n\n\n\n\n\nChart C"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#spatial-data-in-r",
    "href": "pages/2023-01-11/plant-ch-01.html#spatial-data-in-r",
    "title": "Plant ch 01",
    "section": "Spatial Data in R",
    "text": "Spatial Data in R\n\n\n\n\n\nPlant 2019"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#outline",
    "href": "pages/2023-01-11/plant-ch-01.html#outline",
    "title": "Plant ch 01",
    "section": "Outline",
    "text": "Outline\n\n\nCh 01:\n\nOverview\nThe datasets"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#spatial-data-advancements",
    "href": "pages/2023-01-11/plant-ch-01.html#spatial-data-advancements",
    "title": "Plant ch 01",
    "section": "Spatial data advancements",
    "text": "Spatial data advancements\n\n\nIncrease in sensors, increase in available data\nStatistical methods and software\nSo-called spatial data\nsubtleties, but basically geolocated, x and y coordinates\nCRS (Coordinate Reference System[s])"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#sensors-and-satellites",
    "href": "pages/2023-01-11/plant-ch-01.html#sensors-and-satellites",
    "title": "Plant ch 01",
    "section": "Sensors and satellites",
    "text": "Sensors and satellites"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#special-problems",
    "href": "pages/2023-01-11/plant-ch-01.html#special-problems",
    "title": "Plant ch 01",
    "section": "Special problems",
    "text": "Special problems\n\nStatistical properties of spatial data\n\nSpatial data has a lot of data points, so power is large even for tiny effect sizes, thus the Null is always rejected (even if practically meaningless)\nSpatial data points near each other are almost never independent, violating the common assumption that they are (a/k/a spatial autocorrelation)"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#special-problems-1",
    "href": "pages/2023-01-11/plant-ch-01.html#special-problems-1",
    "title": "Plant ch 01",
    "section": "Special problems",
    "text": "Special problems\n\nEcological properties of spatial data\n\nLow ‘ecological resolution’\nHigh ‘data resolution’\nComplex relationships\n\n(next slide shows Soil moisture, Veg reflectance, Yield…)"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#special-problems-2",
    "href": "pages/2023-01-11/plant-ch-01.html#special-problems-2",
    "title": "Plant ch 01",
    "section": "Special problems",
    "text": "Special problems"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#cressies-classification",
    "href": "pages/2023-01-11/plant-ch-01.html#cressies-classification",
    "title": "Plant ch 01",
    "section": "Cressie’s classification",
    "text": "Cressie’s classification\n\n\nGeo-statistical data x-y point data with a continuous measure (like soil moisture). Extrapolation between measured points is a goal.\nAreal data points or polygons representing a uniform unit of measure (like the crop planted within a field boundary)\nPoint pattern data what is the spatial pattern (like whether pest outbreaks are random or spatially explained by some feature)"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#geostatistical-versus-areal",
    "href": "pages/2023-01-11/plant-ch-01.html#geostatistical-versus-areal",
    "title": "Plant ch 01",
    "section": "Geostatistical versus Areal",
    "text": "Geostatistical versus Areal"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#components-of-spatial-data",
    "href": "pages/2023-01-11/plant-ch-01.html#components-of-spatial-data",
    "title": "Plant ch 01",
    "section": "Components of spatial data",
    "text": "Components of spatial data\n\n\nSpatial component (x-y)\nAttribute component (something measured or classified)\nScale and sample size (for measuring earthworms, is 1m or 1000m better to sample?)\nVector data versus Raster data"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-1",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-1",
    "title": "Plant ch 01",
    "section": "Dataset 1",
    "text": "Dataset 1\nYellow billed cuckoo habitat"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-1-1",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-1-1",
    "title": "Plant ch 01",
    "section": "Dataset 1",
    "text": "Dataset 1\nWhat spatial featured are associated with presence in this species? (Data has shapes and attributes)"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-2",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-2",
    "title": "Plant ch 01",
    "section": "Dataset 2",
    "text": "Dataset 2\nOak woodland habitat characteristics"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-2-1",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-2-1",
    "title": "Plant ch 01",
    "section": "Dataset 2",
    "text": "Dataset 2\nWhy does young oak “recruitment” vary?\nData are rows and columns with x-y coords\nInfer where habitat is suitable for oak population growth."
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-3",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-3",
    "title": "Plant ch 01",
    "section": "Dataset 3",
    "text": "Dataset 3\nRice farming, flooding and crop rotation"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-3-1",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-3-1",
    "title": "Plant ch 01",
    "section": "Dataset 3",
    "text": "Dataset 3\nSpatial orientation of fields\nYield, different farmers\nWhat factors affect yield (e.g. why do some farmers do better than others?)"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#dataset-4",
    "href": "pages/2023-01-11/plant-ch-01.html#dataset-4",
    "title": "Plant ch 01",
    "section": "Dataset 4",
    "text": "Dataset 4\nSpatial comparison of yield in 2 fields with identical management and crop history\nPrecision agriculture\nWhat factors affect within-field variation in yield?"
  },
  {
    "objectID": "pages/2023-01-11/plant-ch-01.html#coding",
    "href": "pages/2023-01-11/plant-ch-01.html#coding",
    "title": "Plant ch 01",
    "section": "Coding",
    "text": "Coding"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Our current meeting schedule Wednesdays at 4pm UK time via Teams, and occasionally in person. Join our Slack channel and introduce yourself for more information and to participate (please join with your full real name, e.g. “Florence Nightingale”."
  },
  {
    "objectID": "schedule.html#the-future",
    "href": "schedule.html#the-future",
    "title": "Schedule",
    "section": "The Future",
    "text": "The Future\n2023-12-13 (Meeting #134, room TBA) Beginning R and stats: what training do you want and need? (group discussion led by Ed H)\n2023-12-20 (Meeting #135) Holidays data viz activity (Ed H +…?)\nWinter break\n2024-01-17 Resume for spring term…"
  },
  {
    "objectID": "schedule.html#meeting-topics",
    "href": "schedule.html#meeting-topics",
    "title": "Schedule",
    "section": "Meeting topics",
    "text": "Meeting topics\n  2023-12-06 (Meeting #133) Example experimental design and power (Ronald M) ::: slide files :::\n  2023-11-29 (Meeting #132) Train a custom Yolo model in Python (Ed H) ::: slide files ::: ed owl pic ::: slide files ::: Python notebook html ::: link to Python notebook repo\n  2023-11-22 (Meeting #131) Basics of effect size and power for experimental design in R (Ed H + Charlotte C) ::: Power ppt ::: Cow experiment ppt ::: f^2 Effect size reading Selya 2012\n  2023-11-15 (meeting #130) Cattle welfare data science project (Tom C) ::: stressed cows\n  2023-08-02 (meeting #129) Beginning Python for applied Scientists (and other interesting people) (Ed H) ::: slides ::: data ::: colab notebook ::: Python Resources\n  2023-07-26 (meeting #128) Bioinformatics with and without Galaxy (Sotiria B) ::: slides\n  2023-07-19 (meeting #127) chatGPT + code interpreter for data analysis (Joe R)\n  2023-07-12 (meeting #126) Docker web app demo (Matt B) ::: instructions ::: slides\n  2023-07-05 (meeting #125) Simulation as a tool for experimental design (Ed H) ::: R proj files zip ::: slides\n  2023-06-14 (meeting #124) Docker-related session? (Matt B)\n  2023-06-07 (meeting #123) You’ve heard of ChatGPT, but have you heard of birdNet…? (Sophie C)\n  2023-05-31 (meeting #122) Progress update on DeepLabCut (George W)\n  2023-05-24 (meeting #121) Using ChatGPT to support data analysis - some experimental results (Ed H) chatGPT experiments slides ::: chatGPT prompts ::: milkers project zip\n  2023-05-17 (meeting #120) Large Language Models, ChatGPT, OpenGPT and LangChain: An overview and what you can do right now (Ed H) chatGPT slides ::: chatGPT prompts\n  2023-05-03 (meeting #119) My_Tidy_Data %<% Web scraping data with R and tools like readLines() and grep() (Ed H) Manual scrape project files ::: “Autoscrape” example script\n  2023-04-26 (meeting #118) Part 3: Animal pose and behaviour detection in Deeplabcut (George W)::: DeepLabCut website ::: George W ppt\n  2023-04-19 (meeting #117) Plant Spatial Statistics Ch 03 Part 2 (Przemek D) Chapter 03 ::: Plant ALL DATA\n  2023-04-12 (meeting #116) Part 2: Animal pose and behaviour detection in Deeplabcut (George W)::: DeepLabCut website ::: George W ppt\n  2023-04-05 (meeting #115) Part 1: Animal pose and behaviour detection in Deeplabcut (George W) ::: DeepLabCut website ::: George W ppt\n  2023-03-15 (meeting #114) Plant Spatial Statistics Ch 03 Part 1 (Przemek D) Chapter 03 ::: Plant ALL DATA\n  2023-03-08 (meeting #113) Bootcamp launch S02E02 (George W.) ::: Bootcamp 2\n 2023-02-15 (meeting #112) Natural Language Processing session #02 (Ed) ::: NLP2 slides ::: NLP2 notbook: open from github https://github.com/harper-data-science/aws-nlp :: MLA-NLP-Lecture1.2-BOW.ipynb\n 2023-02-01 (meeting #111) Spatial statistics with R Read Chapter 02 and exercises in Plant 2019 Spatial Data Analysis 2ed (Ed) ::: Plant ch02 ::: html slides ch 02 ::: Plant ALL DATA ::: Plant ALL CODE ::: Ed ch02 code\n  2023-01-25 (meeting #110) Bootcamp launch S02E01 (Ed + HARUG!) ::: Bootcamp1 ::: slides overview ::: slides Setup 01\n  2023-01-18 (meeting #109) Natural Language Processing session #01 (Ed) ::: NLP1 slides ::: NLP1 notbook\n  2023-01-11 (meeting #108) Spatial statistics with R Read Chapters 01 in Plant 2019 Spatial Data Analysis 2ed (Ed) ::: Plant ch01 ::: html slides ::: Plant ALL DATA ::: Plant ALL CODE ::: Ed ch01 code\n  2022-12-07 (meeting #107) Basic of Shiny + R Markdown + {flexdashboard} for interactive data (Ed) ::: pptx\n 2022-11-23 (meeting #106) Future topics survey and cheatsheet activity (Ed) ::: pptx ::: cheatsheet 1 ::: cheatsheet 2 ::: cheatsheet 3 ::: cheatsheet 4\n  2022-11-16 (meeting #105) Earwigs, wooly apple aphids and binomial regression. Oh, my! (Hayden) ::: talk pptx ::: R script ::: Raw data xlsx ::: Count data xlsx\n  2022-11-02 (meeting #104) Tidy data and stats for a mysterious experiment (Eric S)\n  2022-10-26 (meeting #103) Intro to the {mlr3} package in R (Ed) ::: pptx ::: R script ::: {mlr3} book site\n  2022-10-19 (meeting #102) Natural Language Processing (NLP) What is it good for? (Magda)\n  2022-10-12 (meeting #101) Analysis of spatial data (Joe C)\n  2022-10-05 (meeting #100) Quarto: R Markdown’s “new clothes”? Our \\(10^2\\) meeting! (Ed) ::: Quarto Github webpage tutorial\n  2022-09-28 (meeting #99) Computer vision project / Python (Matt) ::: pptx ::: weevilwatch github repo\n 2022-09-21 (meeting #98) New Quarto website (Ed) ::: Quarto Hello, World\n\n\nThis group is supported by the research and teaching community at Harper Adams University and by students and alumnists of the MSc in Data Science for Global Agriculture, Food, and Environment, and is led by Ed Harris."
  },
  {
    "objectID": "pages/2023-07-05-pwr-sim/pwr_report.html",
    "href": "pages/2023-07-05-pwr-sim/pwr_report.html",
    "title": "Power sim for cow nutrition",
    "section": "",
    "text": "The goal here was to simulate power for several sample size scenarios for a 4x4 Latin Square design. A balanced Latin sq. design would typically have an equal replicate size for each cohort (e.g. n=8 [or another multiple of 4], with 2 individuals per cohort with 4 cohorts in a 4x4 design). However only 7 or 6 subjects are available. The question is how does this affect power? I assumed the analysis to be a linear mixed effects model (as an alternative to ANOVA for fully balanced design), with individual Cow as a random effect and Diet treatment (4 levels) as a fixed effect.\n \n\\(y_t = \\beta_0 + \\boldsymbol{B}_1 * (Diet) + (b_s)_t + \\epsilon_t\\)\n \nwhere \\(\\beta_0\\) is the mean response, \\(\\boldsymbol{B}_1\\) is the matrix of Diet-specific effect estimates, \\(b_s\\) is the random effect of subject \\(s\\), and \\(\\epsilon_t\\) is the assumed-Gaussian residual error.\n \nPower analysis for linear mixed effects models can be challenging; here a simulation approach was used (e.g., see Kumle et al. 2021). Pilot data were provided for two dependent variables, pH and Ammonia, and parameter for the simulation model were estimated based on them to simulate statistical power for detecting a treatment effect of Diet for \\(n=\\) 8, 7 or 6 subjects. For each model, 500 datasets were simulated for each sample size, and each sample size was modeled for the observed pilot variance, for +10% observed pilot variance and for -10% observed variance (med, high and low, respectively). The {lme4} package (Bates et al. 2015) was used for the linear mixed effects modelling using R v 4.3.0 (R Core Team 2023). The pilot data only contained three feed treatments, so the four treatment experiment was modeled using the observed treatment extremes, with an extrapolated monotonic increase in effect size for the two other treatments within the range of extremes.\n \nTable 1. The parameter sets used for power simulations."
  },
  {
    "objectID": "pages/2023-07-05-pwr-sim/pwr_report.html#results",
    "href": "pages/2023-07-05-pwr-sim/pwr_report.html#results",
    "title": "Power sim for cow nutrition",
    "section": "Results",
    "text": "Results\nFigure 1. Panels A and B contain the power analysis results for pH and Ammonia, respectively. The red horizontal dashed line indicates 80% power. Each solid line represents a variance value across n = 6,7 or 8 cows. The purple dot indicates expected power for the pilot data parameterised variance (med) for n = 7 cows. Panels C and D show pilot data for pH and Ammonia, respectively. Each line represents a different Cow.\n \nThe expected power for n=7 for pH is slightly below 80% power, while the expected power for all replicate sizes are far above 80% power for Ammonia."
  },
  {
    "objectID": "pages/2023-07-05-pwr-sim/pwr_report.html#references",
    "href": "pages/2023-07-05-pwr-sim/pwr_report.html#references",
    "title": "Power sim for cow nutrition",
    "section": "References",
    "text": "References\nBates, D., Maechler, M., Bolker, B., Walker, S. 2015. Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.\nKumle, L., Võ, M.L.-H., Draschkow, D., 2021. Estimating power in (generalized) linear mixed models: An open introduction and tutorial in R. Behav Res 53, 2528–2543. https://doi.org/10.3758/s13428-021-01546-0\nR Core Team 2023. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html",
    "title": "Harper Data Science",
    "section": "",
    "text": "(Some thoughts on elements of a friendly Python Stats Bootcamp)\nHARUG!\n2023-08-02"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#arithmetic-operations",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#arithmetic-operations",
    "title": "Harper Data Science",
    "section": "Arithmetic operations",
    "text": "Arithmetic operations\nPython supports the usual arithmetic operators: + (addition), * (multiplication), / (division), ** (power), // (integer division)."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#lists",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#lists",
    "title": "Harper Data Science",
    "section": "Lists",
    "text": "Lists\nLists are a container type for ordered sequences of elements. Lists can be initialized empty\n\nmy_list = []\n\nor with some initial elements\n\nmy_list = [1, 2, 3]\n\nLists have a dynamic size and elements can be added (appended) to them\n\nmy_list.append(4)\nmy_list\n\nWe can access individual elements of a list (indexing starts from 0)\n\nmy_list[2]\n\nWe can access “slices” of a list using my_list[i:j] where i is the start of the slice (again, indexing starts from 0) and j the end of the slice. For instance:\n\nmy_list[1:3]\n\nOmitting the second index means that the slice should run until the end of the list\n\nmy_list[1:]\n\nWe can check if an element is in the list using in\n\n5 in my_list\n\nThe length of a list can be obtained using the len function\n\nlen(my_list)"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#strings",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#strings",
    "title": "Harper Data Science",
    "section": "Strings",
    "text": "Strings\nStrings are used to store text. They can be delimited using either single quotes or double quotes\n\nstring1 = \"some text\"\nstring2 = 'some other text'\n\nStrings behave similarly to lists. As such we can access individual elements in exactly the same way\n\nstring1[3]\n\nand similarly for slices\n\nstring1[5:]\n\nString concatenation is performed using the + operator\n\nstring1 + \" \" + string2"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#conditionals",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#conditionals",
    "title": "Harper Data Science",
    "section": "Conditionals",
    "text": "Conditionals\nAs their name indicates, conditionals are a way to execute code depending on whether a condition is True or False. As in other languages, Python supports if and else but else if is contracted into elif, as the example below demonstrates.\n\nmy_variable = 5\nif my_variable < 0:\n  print(\"negative\")\nelif my_variable == 0:\n  print(\"null\")\nelse: # my_variable > 0\n  print(\"positive\")\n\nHere < and > are the strict less and greater than operators, while == is the equality operator (not to be confused with =, the variable assignment operator). The operators <= and >= can be used for less (resp. greater) than or equal comparisons.\nContrary to other languages, blocks of code are delimited using indentation. Here, we use 2-space indentation but many programmers also use 4-space indentation. Any one is fine as long as you are consistent throughout your code."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#loops",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#loops",
    "title": "Harper Data Science",
    "section": "Loops",
    "text": "Loops\nLoops are a way to execute a block of code multiple times. There are two main types of loops: while loops and for loops.\nWhile loop\n\ni = 0\nwhile i < len(my_list):\n  print(my_list[i])\n  i += 1 # equivalent to i = i + 1\n\nFor loop\n\nfor i in range(len(my_list)):\n  print(my_list[i])\n\nIf the goal is simply to iterate over a list, we can do so directly as follows\n\nfor element in my_list:\n  print(element)"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#functions",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#functions",
    "title": "Harper Data Science",
    "section": "Functions",
    "text": "Functions\nTo improve code readability, it is common to separate the code into different blocks, responsible for performing precise actions: functions. A function takes some inputs and process them to return some outputs.\n\ndef square(x):\n  return x ** 2\n\ndef multiply(a, b):\n  return a * b\n\n# Functions can be composed.\nsquare(x = multiply(a = 3, b = 2))\n\n36\n\n\nTo improve code readability, it is sometimes useful to explicitly name the arguments\n\nsquare(multiply(a=3, b=2))"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#try-this-exercise-1",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#try-this-exercise-1",
    "title": "Harper Data Science",
    "section": "Try this (exercise)!",
    "text": "Try this (exercise)!\nExercise 1. Using a conditional, write the relu function defined as follows\n\\(\\text{relu}(x) = \\left\\{  \\begin{array}{rl}  x, & \\text{if } x \\ge 0 \\\\  0, & \\text{otherwise }.  \\end{array}\\right.\\)\n\ndef relu(x):\n  # Write your function here\n  return\n\nrelu(-3)\n\nExercise 2. Using a for loop, write a function that computes the Euclidean norm of a vector, represented as a list.\n\ndef euclidean_norm(vector):\n  # Write your function here\n  return\n\nmy_vector = [0.5, -1.2, 3.3, 4.5]\n# The result should be roughly 5.729746940310715\neuclidean_norm(my_vector)\n\nExercise 3. Using a for loop and a conditional, write a function that returns the maximum value in a vector.\n\ndef vector_maximum(vector):\n  # Write your function here\n  return\n\nBonus exercise. if time permits, write a function that sorts a list in ascending order (from smaller to bigger) using the bubble sort algorithm.\n\ndef bubble_sort(my_list):\n  # Write your function here\n  return\n\nmy_list = [1, -3, 3, 2]\n# Should return [-3, 1, 2, 3]\nbubble_sort(my_list)\n\n\nList of Python tutorials\nFour-hour course on Youtube"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#array-creation",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#array-creation",
    "title": "Harper Data Science",
    "section": "Array creation",
    "text": "Array creation\nNumPy arrays can be created from Python lists\n\nmy_array = np.array([1, 2, 3])\nmy_array\n\nNumPy supports array of arbitrary dimension. For example, we can create two-dimensional arrays (e.g. to store a matrix) as follows\n\nmy_2d_array = np.array([[1, 2, 3], [4, 5, 6]])\nmy_2d_array\n\nWe can access individual elements of a 2d-array using two indices\n\nmy_2d_array[1, 2]\n\nWe can also access rows\n\nmy_2d_array[1]\n\nand columns\n\nmy_2d_array[:, 2]\n\nArrays have a shape attribute\n\nprint(my_array.shape)\nprint(my_2d_array.shape)\n\nContrary to Python lists, NumPy arrays must have a type and all elements of the array must have the same type.\n\nmy_array.dtype\n\nThe main types are int32 (32-bit integers), int64 (64-bit integers), float32 (32-bit real values) and float64 (64-bit real values).\nThe dtype can be specified when creating the array\n\nmy_array = np.array([1, 2, 3], dtype=np.float64)\nmy_array.dtype\n\nWe can create arrays of all zeros using\n\nzero_array = np.zeros((2, 3))\nzero_array\n\nand similarly for all ones using ones instead of zeros.\nWe can create a range of values using\n\nnp.arange(5)\n\nor specifying the starting point\n\nnp.arange(3, 5)\n\nAnother useful routine is linspace for creating linearly spaced values in an interval. For instance, to create 10 values in [0, 1], we can use\n\nnp.linspace(0, 1, 10)\n\nAnother important operation is reshape, for changing the shape of an array\n\nmy_array = np.array([1, 2, 3, 4, 5, 6])\nmy_array.reshape(3, 2)\n\nPlay with these operations and make sure you understand them well."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#basic-operations",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#basic-operations",
    "title": "Harper Data Science",
    "section": "Basic operations",
    "text": "Basic operations\nIn NumPy, we express computations directly over arrays. This makes the code much more succinct.\nArithmetic operations can be performed directly over arrays. For instance, assuming two arrays have a compatible shape, we can add them as follows\n\narray_a = np.array([1, 2, 3])\narray_b = np.array([4, 5, 6])\narray_a + array_b\n\nCompare this with the equivalent computation using a for loop\n\narray_out = np.zeros_like(array_a)\nfor i in range(len(array_a)):\n  array_out[i] = array_a[i] + array_b[i]\narray_out\n\nNot only this code is more verbose, it will also run much more slowly.\nIn NumPy, functions that operates on arrays in an element-wise fashion are called universal functions. For instance, this is the case of np.sin\n\nnp.sin(array_a)\n\nVector inner product can be performed using np.dot\n\nnp.dot(array_a, array_b)\n\nWhen the two arguments to np.dot are both 2d arrays, np.dot becomes matrix multiplication\n\narray_A = np.random.rand(5, 3)\narray_B = np.random.randn(3, 4)\nnp.dot(array_A, array_B)\n\nMatrix transpose can be done using .transpose() or .T for short\n\narray_A.T"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#slicing-and-masking",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#slicing-and-masking",
    "title": "Harper Data Science",
    "section": "Slicing and masking",
    "text": "Slicing and masking\nLike Python lists, NumPy arrays support slicing\n\nnp.arange(10)[5:]\n\nWe can also select only certain elements from the array\n\nx = np.arange(10)\nmask = x >= 5\nx[mask]\n\n\nTry this (exercise)!\nExercise 1. Create a 3d array of shape (2, 2, 2), containing 8 values. Access individual elements and slices.\nExercise 2. Rewrite the relu function (see Python section) using np.maximum. Check that it works on both a single value and on an array of values.\n\ndef relu_numpy(x):\n  return\n\nrelu_numpy(np.array([1, -3, 2.5]))\n\nExercise 3. Rewrite the Euclidean norm of a vector (1d array) using NumPy (without for loop)\n\ndef euclidean_norm_numpy(x):\n  return\n\nmy_vector = np.array([0.5, -1.2, 3.3, 4.5])\neuclidean_norm_numpy(my_vector)\n\nExercise 4. Write a function that computes the Euclidean norms of a matrix (2d array) in a row-wise fashion. Hint: use the axis argument of np.sum.\n\ndef euclidean_norm_2d(X):\n  return\n\nmy_matrix = np.array([[0.5, -1.2, 4.5],\n                      [-3.2, 1.9, 2.7]])\n# Should return an array of size 2.\neuclidean_norm_2d(my_matrix)\n\nExercise 5. Compute the mean value of the features in the iris dataset. Hint: use the axis argument on np.mean.\n\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\n\n# Result should be an array of size 4."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#going-further",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#going-further",
    "title": "Harper Data Science",
    "section": "Going further",
    "text": "Going further\n\nNumPy reference\nSciPy lectures\nOne-hour tutorial on Youtube"
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#basic-plots",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#basic-plots",
    "title": "Harper Data Science",
    "section": "Basic plots",
    "text": "Basic plots\nMatplotlib is a plotting library for Python.\nWe start with a rudimentary plotting example.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nx_values = np.linspace(-3, 3, 100)\n\nplt.figure()\nplt.plot(x_values, np.sin(x_values), label=\"Sinusoid\")\nplt.xlabel(\"x\")\nplt.ylabel(\"sin(x)\")\nplt.title(\"Matplotlib example\")\nplt.legend(loc=\"upper left\")\nplt.show()\n\n\n\n\nWe continue with a rudimentary scatter plot example. This example displays samples from the iris dataset using the first two features. Colors indicate class membership (there are 3 classes).\n\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\n\nX_class0 = X[y == 0]\nX_class1 = X[y == 1]\nX_class2 = X[y == 2]\n\nplt.figure()\nplt.scatter(X_class0[:, 0], X_class0[:, 1], label=\"Class 0\", color=\"C0\")\nplt.scatter(X_class1[:, 0], X_class1[:, 1], label=\"Class 1\", color=\"C1\")\nplt.scatter(X_class2[:, 0], X_class2[:, 1], label=\"Class 2\", color=\"C2\")\nplt.show()\n\n\n\n\nWe see that samples belonging to class 0 can be linearly separated from the rest using only the first two features."
  },
  {
    "objectID": "pages/2023-08-02-Ed-Python/Python_basics.html#exercises",
    "href": "pages/2023-08-02-Ed-Python/Python_basics.html#exercises",
    "title": "Harper Data Science",
    "section": "Exercises",
    "text": "Exercises\nExercise 1. Plot the relu and the softplus functions on the same graph.\nWhat is the main difference between the two functions?\nExercise 2. Repeat the same scatter plot but using the digits dataset instead.\n\nfrom sklearn.datasets import load_digits\nX, y = load_digits(return_X_y=True)\n\nAre pixel values good features for classifying samples?"
  },
  {
    "objectID": "files/2023-11-20-yolo/yolo_intro.html#transfer-learning",
    "href": "files/2023-11-20-yolo/yolo_intro.html#transfer-learning",
    "title": "Harper Data Science",
    "section": "Transfer learning",
    "text": "Transfer learning\nTransfer learning, used in machine learning, is the reuse of a pre-trained model on a new problem. In transfer learning, a machine exploits the knowledge gained from a previous task to improve generalization about another.\nTo do this you need to create your own training data\nWe are going to look at an example today on a platform called Roboflow.\n\n# NB API key is fiddley\n!pip install roboflow\nfrom roboflow import Roboflow\nfrom google.colab import userdata\n\n\nrf = Roboflow(api_key=userdata.get('roboflowkey')) # << explain briefly!\nproject = rf.workspace(\"roboflow-gw7yv\").project(\"raccoon\")\ndataset = project.version(38).download(\"yolov8\")\n\nloading Roboflow workspace...\nloading Roboflow project...\nDependency ultralytics==8.0.196 is required but found version=8.0.220, to fix: `pip install ultralytics==8.0.196`\n\n\nDownloading Dataset Version Zip in Raccoon-38 to yolov8:: 100%|██████████| 11800/11800 [00:00<00:00, 32613.29it/s]\n\n\n\n\n\n\nExtracting Dataset Version Zip to Raccoon-38 in yolov8:: 100%|██████████| 799/799 [00:00<00:00, 8040.91it/s]\n\n\n\n!yolo task=detect \\\nmode = train \\\nmodel = yolov8s.pt \\\ndata = /content/Raccoon-38/data.yaml \\\nepochs = 10 \\\nimgsz = 640\n\nUltralytics YOLOv8.0.220 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\nengine/trainer: task=detect, mode=train, model=yolov8s.pt, data=/content/Raccoon-38/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100% 755k/755k [00:00<00:00, 12.3MB/s]\n2023-11-29 15:19:03.571951: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2023-11-29 15:19:03.572023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2023-11-29 15:19:03.572079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 349/355 items from pretrained weights\nTensorBoard: Start with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nAMP: checks passed ✅\ntrain: Scanning /content/Raccoon-38/train/labels... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:00<00:00, 1576.78it/s]\ntrain: New cache created: /content/Raccoon-38/train/labels.cache\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\nval: Scanning /content/Raccoon-38/valid/labels... 29 images, 0 backgrounds, 0 corrupt: 100% 29/29 [00:00<00:00, 919.25it/s]\nval: New cache created: /content/Raccoon-38/valid/labels.cache\nPlotting labels to runs/detect/train2/labels.jpg... \noptimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \noptimizer: AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to runs/detect/train2\nStarting training for 10 epochs...\nClosing dataloader mosaic\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      3.93G      1.783      7.084      2.412          6        640: 100% 10/10 [00:07<00:00,  1.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.84s/it]\n                   all         29         29      0.666      0.655      0.717      0.279\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      3.99G      1.371      2.883      2.013          8        640: 100% 10/10 [00:02<00:00,  3.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n                   all         29         29      0.603      0.828      0.721      0.277\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      4.01G      1.178      1.829      1.895          6        640: 100% 10/10 [00:02<00:00,  3.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.28it/s]\n                   all         29         29      0.813      0.759      0.807       0.39\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      4.01G       1.26      1.564      1.923          6        640: 100% 10/10 [00:03<00:00,  2.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.17it/s]\n                   all         29         29      0.744      0.703      0.757      0.348\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/10         4G      1.155      1.257      1.845          7        640: 100% 10/10 [00:02<00:00,  3.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.27it/s]\n                   all         29         29      0.632      0.862      0.807      0.364\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      4.01G      1.269       1.26      1.864          7        640: 100% 10/10 [00:02<00:00,  3.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.39it/s]\n                   all         29         29      0.893      0.862      0.928      0.386\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/10         4G      1.111       1.15      1.714          6        640: 100% 10/10 [00:03<00:00,  3.06it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.12it/s]\n                   all         29         29      0.878      0.828      0.882      0.391\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      4.01G      1.183      1.044      1.792          6        640: 100% 10/10 [00:02<00:00,  3.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.09it/s]\n                   all         29         29      0.848      0.966      0.955      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/10         4G       1.08      1.052      1.692          6        640: 100% 10/10 [00:02<00:00,  3.78it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.24it/s]\n                   all         29         29      0.917      0.966      0.958      0.545\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/10         4G      0.962     0.8895      1.587          6        640: 100% 10/10 [00:02<00:00,  3.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.23it/s]\n                   all         29         29      0.893       0.86      0.933      0.555\n\n10 epochs completed in 0.016 hours.\nOptimizer stripped from runs/detect/train2/weights/last.pt, 22.5MB\nOptimizer stripped from runs/detect/train2/weights/best.pt, 22.5MB\n\nValidating runs/detect/train2/weights/best.pt...\nUltralytics YOLOv8.0.220 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.54it/s]\n                   all         29         29      0.893       0.86      0.933      0.555\nSpeed: 0.2ms preprocess, 6.0ms inference, 0.0ms loss, 1.8ms postprocess per image\nResults saved to runs/detect/train2\n💡 Learn more at https://docs.ultralytics.com/modes/train"
  },
  {
    "objectID": "files/2023-11-20-yolo/yolo.html#section",
    "href": "files/2023-11-20-yolo/yolo.html#section",
    "title": "Computer Image Classification",
    "section": "",
    "text": "Venn Diagram of AI and Deep Learning"
  }
]