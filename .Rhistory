## 00 Setup ####
# Ed work PC
setwd(r'(D:\Dropbox\git-harper-data-science\website\scripts)')
insta;;.packages("mlr3")
install.packages("mlr3")
# install.packages("mlr3")
library(mlr3)
### 1.1 Data ####
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
data
### 1.2 create task ####
task_mtcars = as_task_regr(data, target = "mpg", id = "cars")
print(task_mtcars)
install.packages(c("mlr3","mlr3viz")
)
install.packages(c("mlr3", "mlr3viz"))
install.packages(c("mlr3", "mlr3viz"))
install.packages(c("mlr3", "mlr3viz"))
install.packages(c("mlr3", "mlr3viz"))
# install.packages(c("mlr3","mlr3viz"))
library(mlr3)
library(mlr3viz)
### 1.3 viz summary task
mlr3viz::autoplot(task_mtcars, type = pairs)
### 1.3 viz summary task
mlr3viz::autoplot(task_mtcars, type = 'pairs')
# example penguins
task_penguins = tsk("penguins")
print(task_penguins)
mlr3viz::autoplot(task_penguins, type = 'pairs')
print(task_penguins)
### 1.4 Taks descriptives
task_mtcars$nrow
task_mtcars$feature_names
task_mtcars$target_names
library(mlr3proba)
install.packages("mlr3proba")
requireNamespace("mlr3proba", quietly = TRUE)
tsk("unemployment")$target_names
requireNamespace("mlr3proba", quietly = TRUE)
tsk("unemployment")$target_names
# The data contained in a task can be accessed through $data()
task_mtcars$data()
# show summary of entire data
summary(as.data.table(task_mtcars))
### 1.4 mutators ####
# these manupulate task objects with min syntax
task_penguins_small = tsk("penguins")
task_penguins_small
task_penguins_small$select(c("body_mass", "flipper_length")) # keep only these features
task_penguins_small
task_penguins_small$filter(2:4) # keep only these rows
task_penguins_small
task_penguins_small$data()
# keep the 2nd row:
keep = task$row_ids[2] # extracts id of 2nd row
### 1.5 Plotting
library("mlr3viz")
# get the pima indians task
task = tsk("pima")
# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))
# default plot: class frequencies
autoplot(task)
# get the pima indians task
task = tsk("pima")
task
task$feature_names
head(task$feature_names, 3)
# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))
# default plot: class frequencies
autoplot(task)
# pairs plot (requires package GGally)
autoplot(task, type = "pairs")
# duo plot (requires package GGally)
autoplot(task, type = "duo")
library("mlr3learners")       # load recommended learners provided by mlr3learners package
# install.packages("mlr3")
# install.packages("mlr3viz")
# install.packages("mlr3proba")
install.packages("mlr3learners")
install.packages("mlr3extralearners")
install.packages("mlr3proba")
install.packages("mlr3cluster")
library(mlr3learners)       # load recommended learners provided by mlr3learners package
library(mlr3extralearners)  # this loads further less-well-supported learners
install.packages("mlr3extralearners")
install.packages("mlr3proba")
install.packages("mlr3cluster")
mlr_learners
# There are a lot of learners
mlr_learners
# get a learner
learner = lrn("classif.rpart")
learner
learner$param_set
# accessing values
learner$param_set$values
learner$param_set$values$cp
learner$param_set$values$cp <- 0.01
learner$param_set$values
### 2.2 Train a learner
task = tsk("pima")
learner = lrn("classif.rpart")
### 2.2 Train a learner
learner$model
# Now we fit the classification tree using the
# training set of the task by calling the $train()
# method of Learner:
learner$train(task)
# Now we fit the classification tree using the
# training set of the task by calling the $train()
# method of Learner:
learner$train(task)
learner$train(task)
learner$model
plot(learner$model)
autoplot(learner$model)
### 2.3 Predicting
pima_new = data.table::fread("
age, glucose, insulin, mass, pedigree, pregnant, pressure, triceps
24,  145,     306,     41.7, 0.5,      3,        52,       36
47,  133,     NA,      23.3, 0.2,      7,        83,       28
")
pima_new
prediction = learner$predict_newdata(pima_new)
prediction
# with truth column
pima_new_known = cbind(pima_new, diabetes = factor("pos", levels = c("pos", "neg")))
pima_new_known
prediction = learner$predict_newdata(pima_new_known)
prediction
### 2.3 prediction type ####
learner$predict_type = "prob"
# re-fit the model
learner$train(task)
# rebuild prediction object
prediction = learner$predict(task_pima_new)
prediction
task_pima_new = as_task_classif(pima_new_known, target = "diabetes")
prediction = learner$predict(task_pima_new)
prediction
learner$predict_type = "prob"
# re-fit the model
learner$train(task)
# rebuild prediction object
prediction = learner$predict(task_pima_new)
prediction$confusion
prediction <- learner$predict(task_pima)
prediction <- learner$predict(task)
prediction$confusion
### 2.4 plotting predictions
task = tsk("penguins")
learner = lrn("classif.rpart", predict_type = "prob")
learner$train(task)
prediction = learner$predict(task)
library("mlr3viz")
autoplot(prediction)
## test
task_iris = as_task_classif(iris, target = "species")
## test
task_iris = as_task_classif(iris, target = "Species")
learner$train(task_iris)
prediction = learner$predict(task)
task_iris
learner = lrn("classif.rpart", predict_type = "prob")
learner$train(iris)
learner$train(task_iris)
prediction = learner$predict(task)
prediction = learner$predict(task_iris)
library("mlr3viz")
autoplot(prediction)
v2 <- c(0,0,6)
barplot(v2)
barplot(v2, labels = v1)
at <- barplot(v2)
mtext(v2, at = at)
mtext(v2, 1, at = at)
mtext(v1, 1, at = at)
v1 <- c('R', 'Python', 'Both')
at <- barplot(v2)
mtext(v1, 1, at = at)
at <- barplot(v2,
main = 'R, Python or both?')
mtext(v1, 1, at = at)
#####
v1 <- c('Beginner', 'Medium', 'Advanced')
v2 <- c(1,2,3)
at <- barplot(v2,
main = 'R journey')
mtext(v1, 1, at = at)
#####
v1 <- c('Beginner', 'Medium', 'Advanced')
v2 <- c(3,4,0)
at <- barplot(v2,
main = 'Python journey')
mtext(v1, 1, at = at)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(5,0,2)
at <- barplot(v2,
main = 'Book interest: Statistical Rethinking')
mtext(v1, 1, at = at)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(8,0,2)
at <- barplot(v2,
main = 'Book interest: Plant Spatial statistics')
mtext(v1, 1, at = at)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(5,0,2)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(5,1,2)
at <- barplot(v2,
main = 'Topic interest: Deep learning')
mtext(v1, 1, at = at)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(4,2,3)
at <- barplot(v2,
main = 'R Stats Bootcamp')
mtext(v1, 1, at = at)
#####
v1 <- c('Yes', 'No', 'Maybe')
v2 <- c(7,0,0)
at <- barplot(v2,
main = 'MENTOR R Stats Bootcamp')
mtext(v1, 1, at = at)
9/55
21250/407
21250/407*7.5
